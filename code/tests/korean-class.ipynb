{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import faiss\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "index_path = r\"C:\\Users\\user\\Documents\\code\\korean_food_detection\\tools\\faiss_index_cheat.index\"\n",
    "labels_path = r\"C:\\Users\\user\\Documents\\code\\korean_food_detection\\tools\\labels_cheat.npy\"\n",
    "train_path = r\"C:\\Users\\user\\Documents\\code\\korean_food_detection\\korean_cheat\\train\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\code\\korean_food_detection\\.venv\\Lib\\site-packages\\PIL\\Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to C:\\Users\\user\\Documents\\code\\korean_food_detection\\tools\\faiss_index_cheat.index\n",
      "Labels saved to C:\\Users\\user\\Documents\\code\\korean_food_detection\\tools\\labels_cheat.npy\n"
     ]
    }
   ],
   "source": [
    "class FoodImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_folder in os.listdir(root_dir):\n",
    "            class_path = os.path.join(root_dir, class_folder)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    img_path = os.path.join(class_path, img_file)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(class_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Resize image to 512x512 to match YOLO training input scale\n",
    "        image = image.resize((512, 512))\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "\n",
    "\n",
    "def create_and_save_faiss_index_with_labels(model, dataloader, transform, device, index_path, labels_path):\n",
    "    \"\"\"\n",
    "    Extracts embeddings and saves both FAISS index and labels.\n",
    "\n",
    "    Args:\n",
    "    - model: The pre-trained CLIP model.\n",
    "    - dataloader: DataLoader object for images.\n",
    "    - transform: Image preprocessing transform.\n",
    "    - device: The device (cuda or cpu) for model inference.\n",
    "    - index_path: Path to save the FAISS index.\n",
    "    - labels_path: Path to save the labels.\n",
    "\n",
    "    Returns:\n",
    "    - FAISS index and corresponding labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, label_batch in dataloader:\n",
    "            images = images.to(device)\n",
    "            image_features = model.encode_image(images).cpu().numpy()\n",
    "            \n",
    "            # Append the embeddings and labels\n",
    "            embeddings.append(image_features)\n",
    "            labels.extend(label_batch)  # Extend the list with batch of labels\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)  # Concatenate all embeddings\n",
    "\n",
    "    # Create FAISS index\n",
    "    d = embeddings.shape[1]  # Dimensionality of embeddings\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Save FAISS index to disk\n",
    "    faiss.write_index(index, index_path)\n",
    "    print(f\"FAISS index saved to {index_path}\")\n",
    "\n",
    "    # Save labels to disk\n",
    "    np.save(labels_path, np.array(labels))  # Save the labels as a numpy array\n",
    "    print(f\"Labels saved to {labels_path}\")\n",
    "\n",
    "    return index, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load the CLIP model (ViT-L/14@336px in this case)\n",
    "    model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "    # Dataset and DataLoader (with resize to 512x512)\n",
    "    dataset = FoodImageDataset(root_dir=train_path, transform=preprocess)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Create and save FAISS index and labels\n",
    "    faiss_index, labels = create_and_save_faiss_index_with_labels(\n",
    "        model, dataloader, preprocess, device, index_path, labels_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faiss_index(index_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    print(f\"FAISS index loaded from {index_path}\")\n",
    "    return index\n",
    "def clip_transform(image):\n",
    "    return preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(model, faiss_index, image, transform, device, labels):\n",
    "    \"\"\"\n",
    "    Classify an image using the CLIP model and FAISS index.\n",
    "\n",
    "    Args:\n",
    "    - model: The pre-trained CLIP model.\n",
    "    - faiss_index: The FAISS index with image embeddings.\n",
    "    - image: The input image to classify (PIL Image).\n",
    "    - transform: The preprocessing transform used for the image (same as the one for training).\n",
    "    - device: The device to run the model on (cuda or cpu).\n",
    "    - labels: The list of labels corresponding to the FAISS index embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - The predicted label for the given image or None if no match is found.\n",
    "    \"\"\"\n",
    "    # Check if FAISS index is empty\n",
    "    if faiss_index.ntotal == 0:\n",
    "        print(\"FAISS index is empty, no embeddings available for search.\")\n",
    "        return None\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the input image\n",
    "    with torch.no_grad():\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Extract image features using the CLIP model\n",
    "        image_features = model.encode_image(image).cpu().numpy()\n",
    "\n",
    "        # Search in the FAISS index for the nearest neighbor\n",
    "        distances, indices = faiss_index.search(image_features, k=1)  # k=1 to get the closest match\n",
    "\n",
    "        # Check if we got a valid result\n",
    "        if len(indices) == 0 or len(indices[0]) == 0:\n",
    "            print(\"No match found in the FAISS index.\")\n",
    "            return None\n",
    "\n",
    "        # Get the index of the closest match\n",
    "        closest_idx = indices[0][0]\n",
    "\n",
    "        # Check if the index is within the valid range of labels\n",
    "        if closest_idx >= len(labels):\n",
    "            print(\"Closest index is out of bounds for labels.\")\n",
    "            return None\n",
    "\n",
    "        # Return the corresponding label\n",
    "        predicted_label = labels[closest_idx]\n",
    "        return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels_path):\n",
    "    \"\"\"\n",
    "    Load labels from a saved numpy file.\n",
    "    \n",
    "    Args:\n",
    "    - labels_path: Path to the saved labels file.\n",
    "    \n",
    "    Returns:\n",
    "    - List of labels.\n",
    "    \"\"\"\n",
    "    return np.load(labels_path, allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model_on_test_data(model, faiss_index, test_root_dir, transform, device, labels):\n",
    "    \"\"\"\n",
    "    Evaluate the CLIP model using the FAISS index on test images organized in folders by class.\n",
    "    Detects and prints the misclassified samples.\n",
    "\n",
    "    Args:\n",
    "    - model: The pre-trained CLIP model.\n",
    "    - faiss_index: The FAISS index with image embeddings.\n",
    "    - test_root_dir: Root directory of the test data, where each subfolder is a class.\n",
    "    - transform: The preprocessing transform used for the image (same as the one for training).\n",
    "    - device: The device to run the model on (cuda or cpu).\n",
    "    - labels: The list of labels corresponding to the FAISS index embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: The accuracy of the model on the test dataset.\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Traverse the test directory\n",
    "    for class_folder in os.listdir(test_root_dir):\n",
    "        class_path = os.path.join(test_root_dir, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                # Get the true label (folder name is the true label)\n",
    "                true_label = class_folder\n",
    "                true_labels.append(true_label)\n",
    "\n",
    "                # Classify the image using the CLIP model and FAISS index\n",
    "                predicted_label = classify_image(model, faiss_index, image, transform, device, labels)\n",
    "                predicted_labels.append(predicted_label)\n",
    "\n",
    "                # Check if the prediction is incorrect\n",
    "                if predicted_label != true_label:\n",
    "                    print(f\"Misclassified image: {img_path}\")\n",
    "                    print(f\"True label: {true_label}, Predicted label: {predicted_label}\\n\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test_data(model, faiss_index, test_root_dir, transform, device, labels, output_file=\"misclassified_images_1.csv\"):\n",
    "    \"\"\"\n",
    "    Evaluate the CLIP model using the FAISS index on test images organized in folders by class.\n",
    "    Detects and logs the misclassified samples to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    - model: The pre-trained CLIP model.\n",
    "    - faiss_index: The FAISS index with image embeddings.\n",
    "    - test_root_dir: Root directory of the test data, where each subfolder is a class.\n",
    "    - transform: The preprocessing transform used for the image (same as the one for training).\n",
    "    - device: The device to run the model on (cuda or cpu).\n",
    "    - labels: The list of labels corresponding to the FAISS index embeddings.\n",
    "    - output_file: The file path where the misclassified samples will be saved (default is 'misclassified_images.csv').\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: The accuracy of the model on the test dataset.\n",
    "    \"\"\"\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Open the file to write misclassifications with utf-8 encoding\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"Image Path,True Label,Predicted Label\\n\")  # Header for CSV\n",
    "\n",
    "        # Traverse the test directory\n",
    "        for class_folder in os.listdir(test_root_dir):\n",
    "            class_path = os.path.join(test_root_dir, class_folder)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    img_path = os.path.join(class_path, img_file)\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                    # Get the true label (folder name is the true label)\n",
    "                    true_label = class_folder\n",
    "                    true_labels.append(true_label)\n",
    "\n",
    "                    # Classify the image using the CLIP model and FAISS index\n",
    "                    predicted_label = classify_image(model, faiss_index, image, transform, device, labels)\n",
    "                    predicted_labels.append(predicted_label)\n",
    "\n",
    "                    # Check if the prediction is incorrect\n",
    "                    if predicted_label != true_label:\n",
    "                        # Save the misclassified image path and labels to the file\n",
    "                        file.write(f\"{img_path},{true_label},{predicted_label}\\n\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from C:\\Users\\user\\Documents\\code\\korean_food_detection\\tools\\faiss_index_cheat.index\n",
      "Model accuracy: 88.71%\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a test directory where each folder is a class\n",
    "test_root_dir = r'C:\\Users\\user\\Documents\\code\\korean_food_detection\\korean_cheat\\test'\n",
    "# Load the FAISS index and labels\n",
    "faiss_index = load_faiss_index(index_path)\n",
    "labels = load_labels(labels_path)\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model_on_test_data(model, faiss_index, test_root_dir, clip_transform, device, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
